{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path('<path_to_brain_multicoil_val>')\n",
    "val_dir = pathlib.Path('<path_to_brain_multicoil_train>')\n",
    "\n",
    "def remove_kspace(path):\n",
    "    for fname in path.iterdir():\n",
    "        if not fname.name.endswith('.h5'):\n",
    "            continue  # Skip directories\n",
    "        new_dir = fname.parent.parent / pathlib.Path(str(fname.parent.name) + '_no_kspace')\n",
    "        if not new_dir.exists():\n",
    "            new_dir.mkdir(parents=False)\n",
    "        new_filename = new_dir / fname.name\n",
    "        if new_filename.exists():\n",
    "            continue  # Skip already done files\n",
    "        f = h5py.File(fname, 'r')\n",
    "        fn = h5py.File(new_filename, 'w')   \n",
    "        for at in f.attrs:\n",
    "            fn.attrs[at] = f.attrs[at]\n",
    "        for dat in f:\n",
    "            if dat == 'kspace':\n",
    "                continue\n",
    "            f.copy(dat, fn)\n",
    "\n",
    "# Run the calls below to remove the stored kspace from multicoil_ brain .h5 file, which will save on I/O later.\n",
    "# We don't need the multicoil kspace since we will construct singlecoil kspace from the ground truth images.\n",
    "# Commented out for safety.\n",
    "\n",
    "# remove_kspace(train_dir)\n",
    "# remove_kspace(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(orig_train_dir, target_test_dir, test_frac):\n",
    "    \"\"\"\n",
    "    Creates a train and test split from the provided training data. Works by\n",
    "    moving random volumes from the training directory to a new test directory.\n",
    "\n",
    "    WARNING: Only use this function once to create the required datasets!\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "\n",
    "    files = sorted(list(orig_train_dir.iterdir()))\n",
    "    target_test_dir.mkdir(parents=False, exist_ok=False)\n",
    "\n",
    "    permutation = np.random.permutation(len(files))\n",
    "    test_indices = permutation[:int(len(files) * test_frac)]\n",
    "    test_files = list(np.array(files)[test_indices])\n",
    "\n",
    "    for i, file in enumerate(test_files):\n",
    "        print(\"Moving file {}/{}\".format(i + 1, len(test_files)))\n",
    "        shutil.move(file, target_test_dir / file.name)\n",
    "        \n",
    "        \n",
    "def count_slices(data_dir, dataset):\n",
    "    vol_count, slice_count = 0, 0\n",
    "    for fname in data_dir.iterdir():\n",
    "        with h5py.File(fname, 'r') as data:\n",
    "            if dataset == 'knee':\n",
    "                gt = data['reconstruction_esc'].value\n",
    "            else:\n",
    "                gt = data['reconstruction_rss'].value\n",
    "            vol_count += 1\n",
    "            slice_count += gt.shape[0]\n",
    "    print(f'{vol_count} volumes, {slice_count} slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For both Knee and Brain data, split off 20% of train as test\n",
    "dataset = 'knee'  # or 'brain'\n",
    "train_dir = pathlib.Path('<path_to_train_data>')\n",
    "val_dir = pathlib.Path('<path_to_val_data>')\n",
    "test_dir = pathlib.Path('<path_to_store_test_data>')\n",
    "\n",
    "test_frac = 0.2\n",
    "\n",
    "# Run this to split of test_frac of train data into test data.\n",
    "# Commented out for safety.\n",
    "\n",
    "# create_train_test_split(train_dir, test_dir, test_frac)\n",
    "\n",
    "count_slices(train_dir, dataset)\n",
    "count_slices(val_dir, dataset)\n",
    "count_slices(test_dir, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rim",
   "language": "python",
   "name": "rim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
